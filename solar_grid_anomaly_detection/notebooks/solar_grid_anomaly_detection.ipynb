{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Power Grid Sensor Anomaly Detection\n",
    "\n",
    "This notebook demonstrates the implementation of an LSTM-based autoencoder for anomaly detection in solar power grid sensor data. The system is designed to identify unusual patterns in time-series data from solar grid sensors that may indicate faults, failures, or other issues requiring attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from utils.data_generator import generate_solar_sensor_data, create_sequences, train_test_split\n",
    "from utils.visualization import (\n",
    "    plot_time_series, \n",
    "    plot_reconstruction, \n",
    "    plot_reconstruction_error,\n",
    "    plot_evaluation_metrics\n",
    ")\n",
    "from models.lstm_autoencoder import LSTMAutoencoder\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Solar Grid Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate solar sensor data\n",
    "df = generate_solar_sensor_data(\n",
    "    num_days=30,\n",
    "    num_sensors=5,\n",
    "    sampling_interval_minutes=15,\n",
    "    noise_level=0.05,\n",
    "    anomaly_prob=0.02,\n",
    "    anomaly_scale=3.0\n",
    ")\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data with anomalies\n",
    "sensor_cols = [f'sensor_{i+1}' for i in range(5)]\n",
    "plot_time_series(df, sensor_cols, anomaly_col='anomaly', figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Create sequences for the LSTM autoencoder and prepare train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequence length and target columns\n",
    "seq_length = 24  # 6 hours with 15-minute sampling\n",
    "target_cols = [f'sensor_{i+1}' for i in range(5)]\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(df, target_cols, seq_length)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f\"Train shapes: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"Test shapes: X_test {X_test.shape}, y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Autoencoder Model\n",
    "\n",
    "Initialize and train the LSTM autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_dim = len(target_cols)  # Number of features\n",
    "hidden_dim = 64\n",
    "latent_dim = 32\n",
    "num_layers = 2\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMAutoencoder(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    seq_len=seq_length,\n",
    "    num_layers=num_layers\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Create batches\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        # Get batch\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_X = X_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_X)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Average training loss\n",
    "    train_loss /= num_batches\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, 'b-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection and Evaluation\n",
    "\n",
    "Use the trained autoencoder to detect anomalies and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction error on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get reconstructions for test data\n",
    "    test_reconstructions = model(X_test_tensor)\n",
    "    \n",
    "    # Compute reconstruction errors\n",
    "    test_errors = model.get_reconstruction_error(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# Plot example reconstructions\n",
    "X_test_np = X_test_tensor.cpu().numpy()\n",
    "reconstructions_np = test_reconstructions.cpu().numpy()\n",
    "\n",
    "# Show a normal example\n",
    "normal_idx = np.where(y_test == 0)[0][0]\n",
    "plot_reconstruction(X_test_np, reconstructions_np, idx=normal_idx, figsize=(12, 6))\n",
    "plt.suptitle('Normal Sequence: Original vs Reconstructed', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Find and show an anomalous example\n",
    "anomaly_idx = np.where(y_test == 1)[0][0]\n",
    "plot_reconstruction(X_test_np, reconstructions_np, idx=anomaly_idx, figsize=(12, 6))\n",
    "plt.suptitle('Anomalous Sequence: Original vs Reconstructed', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction error with true anomalies\n",
    "anomaly_indices = np.where(y_test == 1)[0]\n",
    "plot_reconstruction_error(test_errors, anomaly_indices=anomaly_indices, figsize=(14, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold for anomaly detection\n",
    "fig, optimal_threshold = plot_evaluation_metrics(y_test, test_errors)\n",
    "plt.show()\n",
    "print(f\"Optimal threshold: {optimal_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold and compute metrics\n",
    "y_pred = (test_errors >= optimal_threshold).astype(int)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Interpretation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize latent space\n",
    "with torch.no_grad():\n",
    "    # Get latent representations\n",
    "    latent_vectors = model.encoder(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# Plot latent space with PCA if dimensions are high\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if latent_dim > 2:\n",
    "    pca = PCA(n_components=2)\n",
    "    latent_2d = pca.fit_transform(latent_vectors)\n",
    "else:\n",
    "    latent_2d = latent_vectors\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=y_test, cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='Anomaly')\n",
    "plt.title('Latent Space Visualization')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = '../models/lstm_autoencoder.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'threshold': optimal_threshold,\n",
    "    'hyperparameters': {\n",
    "        'input_dim': input_dim,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'latent_dim': latent_dim,\n",
    "        'seq_len': seq_length,\n",
    "        'num_layers': num_layers\n",
    "    }\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've implemented an LSTM autoencoder for anomaly detection in solar power grid sensor data. The key components include:\n",
    "\n",
    "1. Synthetic data generation with realistic patterns and anomalies\n",
    "2. LSTM-based autoencoder architecture for time series data\n",
    "3. Training and evaluation of the model\n",
    "4. Anomaly detection using reconstruction error\n",
    "5. Visualization and interpretation of results\n",
    "\n",
    "Future enhancements could include:\n",
    "- Testing with real-world solar grid data\n",
    "- Adding weather data as additional features\n",
    "- Implementing online learning for continuous model updates\n",
    "- Developing an alerting system based on detected anomalies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}